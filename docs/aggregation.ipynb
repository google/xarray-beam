{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf2f2cb",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "Xarray-Beam can perform efficient distributed data aggregation in the \"map-reduce\" model. \n",
    "\n",
    "This currently only includes `Mean`, but we would welcome contributions of other aggregation functions such as `Sum`, `Std`, `Var`, `Min`, `Max`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77b953",
   "metadata": {},
   "source": [
    "## High-level API\n",
    "\n",
    "The `Mean` transformation comes in three forms:  {py:class}`Mean <xarray_beam.Mean>`, {py:class}`Mean.Globally <xarray_beam.Mean.Globally>`, and {py:class}`Mean.PerKey <xarray_beam.Mean.PerKey>`. The implementation is highly scalable, based on a Beam's [`CombineFn`](https://beam.apache.org/documentation/transforms/python/aggregation/combineglobally/#example-4-combining-with-a-combinefn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39719ac3",
   "metadata": {},
   "source": [
    "The high-level `Mean` transform can be used to aggregate a distributed dataset across an existing dimension or dimensions, similar to Xarray's `.mean()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d6f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import numpy as np\n",
    "import xarray_beam as xbeam\n",
    "import xarray\n",
    "\n",
    "ds = xarray.tutorial.load_dataset('air_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18bb1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[6]: Mean/PerKey/CombinePerKey(MeanCombineFn)/GroupByKey'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[6]: Mean/PerKey/CombinePerKey(MeanCombineFn)/GroupByKey'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[6]: Mean/PerKey/CombinePerKey(MeanCombineFn)'. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Key(offsets={'lat': 0, 'lon': 0}, vars=None), <xarray.Dataset>\n",
      "Dimensions:  (lat: 25, lon: 53)\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
      "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
      "Data variables:\n",
      "    air      (lat, lon) float64 260.4 260.2 259.9 259.5 ... 297.3 297.3 297.3)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    p | xbeam.DatasetToChunks(ds, chunks={'time': 1000}) | xbeam.Mean('time') | beam.Map(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65232829",
   "metadata": {},
   "source": [
    "## Lower-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabaf15a",
   "metadata": {},
   "source": [
    "Xarray-Beam also includes lower-level transforations modelled off of [`beam.Mean`](https://beam.apache.org/documentation/transforms/python/aggregation/mean/) rather than {py:meth}`xarray.Dataset.mean`: they compute averages over sequences of `xarray.Dataset` objects or (`key`, `xarray.Dataset`) pairs, rather than calculating an average over an existing Xarray dimension or based on `xarray_beam.Key` objects, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a925af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/Users/shoyer/miniconda3/envs/xarray-beam/lib/python3.9/site-packages/ipykernel_launcher.py', '-f', '/Users/shoyer/Library/Jupyter/runtime/kernel-b19331c2-e263-4737-bd64-012081154884.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<xarray.Dataset>\n",
       " Dimensions:  (x: 3)\n",
       " Dimensions without coordinates: x\n",
       " Data variables:\n",
       "     foo      (x) float64 0.1437 0.02742 0.1076]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [\n",
    "    xarray.Dataset({'foo': ('x', np.random.randn(3))})\n",
    "    for _ in range(100)\n",
    "]\n",
    "datasets | xbeam.Mean.Globally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670130b",
   "metadata": {},
   "source": [
    "Notice how existing dimensions on each datasets are unchanged by the transformation. If you want to average over existing dimension, you would need to do that aggregation yourself, e.g., by averaging inside each chunk before combining the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab152b6",
   "metadata": {},
   "source": [
    "Similarly, the keys fed into `xbeam.Mean.PerKey` can be any hashables, including but not limited to `xbeam.Key`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2399483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/Users/shoyer/miniconda3/envs/xarray-beam/lib/python3.9/site-packages/ipykernel_launcher.py', '-f', '/Users/shoyer/Library/Jupyter/runtime/kernel-e19c251a-dc50-467c-aaed-1252152cd403.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('DJF',\n",
       "  <xarray.Dataset>\n",
       "  Dimensions:  ()\n",
       "  Data variables:\n",
       "      air      float64 273.6),\n",
       " ('MAM',\n",
       "  <xarray.Dataset>\n",
       "  Dimensions:  ()\n",
       "  Data variables:\n",
       "      air      float64 279.0),\n",
       " ('JJA',\n",
       "  <xarray.Dataset>\n",
       "  Dimensions:  ()\n",
       "  Data variables:\n",
       "      air      float64 289.2),\n",
       " ('SON',\n",
       "  <xarray.Dataset>\n",
       "  Dimensions:  ()\n",
       "  Data variables:\n",
       "      air      float64 283.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [\n",
    "    (time.dt.season.item(), ds.sel(time=time).mean())\n",
    "    for time in ds.time\n",
    "]\n",
    "datasets | xbeam.Mean.PerKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db1627",
   "metadata": {},
   "source": [
    "For an example of using `Mean.PerKey` at scale, that a look at the [ERA5 climatology example](https://github.com/google/xarray-beam/blob/main/examples/era5_climatology.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6fc6a",
   "metadata": {},
   "source": [
    "## Custom aggregations\n",
    "\n",
    "The \"tree reduction\" algorithm used by the combiner inside `Mean` is great, but it isn't the only way to aggregate a dataset with Xarray-Beam.\n",
    "\n",
    "In many cases, the easiest way to scale up an aggregation pipeline is to make use of [rechunking](rechunking.ipynb) to convert the many small datasets inside your pipeline into a form that is easier to calculate in a scalable way. For example, here's how one could compute the `median`, which is a notoriously difficult statistic to calculate with distributed algoirthms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1ef099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: Rechunk/Stage0/Consolidate/GroupByTempKeys'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: Rechunk/Stage0/Consolidate/GroupByTempKeys'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: Rechunk/Stage2/Consolidate/GroupByTempKeys'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: Rechunk/Stage2/Consolidate/GroupByTempKeys'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: ConsolidateChunks/GroupByTempKeys'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'xarray_beam._src.core.Key'>' in '[3]: ConsolidateChunks/GroupByTempKeys'. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 25, lon: 53)\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n",
      "  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n",
      "Data variables:\n",
      "    air      (lat, lon) float32 261.3 261.1 260.9 260.3 ... 297.3 297.3 297.3\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "source_chunks = {'time': 100, 'lat': -1, 'lon': -1}\n",
    "working_chunks = {'lat': 10, 'lon': 10, 'time': -1}\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (\n",
    "        p\n",
    "        | xbeam.DatasetToChunks(ds, source_chunks)\n",
    "        | xbeam.Rechunk(ds.sizes, source_chunks, working_chunks, itemsize=4)\n",
    "        | beam.MapTuple(lambda k, v: (k.with_offsets(time=None), v.median('time')))\n",
    "        | xbeam.ConsolidateChunks({'lat': -1, 'lon': -1})\n",
    "        | beam.MapTuple(lambda k, v: print(v))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
